{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>396</td>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>397</td>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>398</td>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>399</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>400</td>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0             1        337          118                  4  4.5   4.5  9.65   \n",
       "1             2        324          107                  4  4.0   4.5  8.87   \n",
       "2             3        316          104                  3  3.0   3.5  8.00   \n",
       "3             4        322          110                  3  3.5   2.5  8.67   \n",
       "4             5        314          103                  2  2.0   3.0  8.21   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "395         396        324          110                  3  3.5   3.5  9.04   \n",
       "396         397        325          107                  3  3.0   3.5  9.11   \n",
       "397         398        330          116                  4  5.0   4.5  9.45   \n",
       "398         399        312          103                  3  3.5   4.0  8.78   \n",
       "399         400        333          117                  4  5.0   4.0  9.66   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "0           1              0.92  \n",
       "1           1              0.76  \n",
       "2           1              0.72  \n",
       "3           1              0.80  \n",
       "4           0              0.65  \n",
       "..        ...               ...  \n",
       "395         1              0.82  \n",
       "396         1              0.84  \n",
       "397         1              0.91  \n",
       "398         0              0.67  \n",
       "399         1              0.95  \n",
       "\n",
       "[400 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "admission=pd.read_csv(\"Admission_Predict.csv\")\n",
    "\n",
    "admission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial No.           0\n",
       "GRE Score            0\n",
       "TOEFL Score          0\n",
       "University Rating    0\n",
       "SOP                  0\n",
       "LOR                  0\n",
       "CGPA                 0\n",
       "Research             0\n",
       "Chance of Admit      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admission.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X=admission[['CGPA','University Rating','Research']]\n",
    "\n",
    "Y=admission['Chance of Admit ']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CGPA                 300\n",
       "University Rating    300\n",
       "Research             300\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "c=LinearRegression()\n",
    "\n",
    "c.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84898092, 0.93924463, 0.88424798, 0.68474663, 0.68401711,\n",
       "       0.52565195, 0.5688842 , 0.82995873, 0.65223075, 0.68988624,\n",
       "       0.511477  , 0.69339308, 0.52114534, 0.76977421, 0.7486821 ,\n",
       "       0.82995873, 0.56542562, 0.91157599, 0.79364364, 0.6380558 ,\n",
       "       0.5633557 , 0.93232747, 0.69200442, 0.75525863, 0.90465883,\n",
       "       0.73937651, 0.66947539, 0.83202865, 0.90154088, 0.5861771 ,\n",
       "       0.78360853, 0.62110353, 0.66053657, 0.52738124, 0.55125067,\n",
       "       0.94270321, 0.63800754, 0.54155619, 0.47204396, 0.6968034 ,\n",
       "       0.60381063, 0.85657934, 0.71621448, 0.89428309, 0.87906011,\n",
       "       0.46166822, 0.8047489 , 0.64704288, 0.76804492, 0.68988624,\n",
       "       0.71029709, 0.73311849, 0.56715491, 0.63493785, 0.75386997,\n",
       "       0.77362168, 0.7127559 , 0.67298223, 0.61138693, 0.96033674,\n",
       "       0.58924679, 0.52565195, 0.60726921, 0.76704515, 0.66740547,\n",
       "       0.86661445, 0.55470925, 0.7411058 , 0.94304384, 0.73869525,\n",
       "       0.73450715, 0.90154088, 0.50974771, 0.60692858, 0.79644308,\n",
       "       0.93751534, 0.97417106, 0.85105084, 0.64146612, 0.68335797,\n",
       "       0.7591061 , 0.7832679 , 0.4423054 , 0.67332286, 0.93924463,\n",
       "       0.91710449, 0.79230324, 0.64843154, 0.75214068, 0.54847335,\n",
       "       0.47862049, 0.60308111, 0.60692858, 0.80263072, 0.66918302,\n",
       "       0.70756803, 0.63420833, 0.62071464, 0.72659022, 0.9153752 ])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68     0.68\n",
       "284    0.94\n",
       "285    0.93\n",
       "295    0.68\n",
       "379    0.71\n",
       "       ... \n",
       "116    0.56\n",
       "352    0.64\n",
       "20     0.64\n",
       "246    0.72\n",
       "187    0.93\n",
       "Name: Chance of Admit , Length: 100, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7570532075037095"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84898092, 0.93924463, 0.88424798, 0.68474663, 0.68401711,\n",
       "       0.52565195, 0.5688842 , 0.82995873, 0.65223075, 0.68988624,\n",
       "       0.511477  , 0.69339308, 0.52114534, 0.76977421, 0.7486821 ,\n",
       "       0.82995873, 0.56542562, 0.91157599, 0.79364364, 0.6380558 ,\n",
       "       0.5633557 , 0.93232747, 0.69200442, 0.75525863, 0.90465883,\n",
       "       0.73937651, 0.66947539, 0.83202865, 0.90154088, 0.5861771 ,\n",
       "       0.78360853, 0.62110353, 0.66053657, 0.52738124, 0.55125067,\n",
       "       0.94270321, 0.63800754, 0.54155619, 0.47204396, 0.6968034 ,\n",
       "       0.60381063, 0.85657934, 0.71621448, 0.89428309, 0.87906011,\n",
       "       0.46166822, 0.8047489 , 0.64704288, 0.76804492, 0.68988624,\n",
       "       0.71029709, 0.73311849, 0.56715491, 0.63493785, 0.75386997,\n",
       "       0.77362168, 0.7127559 , 0.67298223, 0.61138693, 0.96033674,\n",
       "       0.58924679, 0.52565195, 0.60726921, 0.76704515, 0.66740547,\n",
       "       0.86661445, 0.55470925, 0.7411058 , 0.94304384, 0.73869525,\n",
       "       0.73450715, 0.90154088, 0.50974771, 0.60692858, 0.79644308,\n",
       "       0.93751534, 0.97417106, 0.85105084, 0.64146612, 0.68335797,\n",
       "       0.7591061 , 0.7832679 , 0.4423054 , 0.67332286, 0.93924463,\n",
       "       0.91710449, 0.79230324, 0.64843154, 0.75214068, 0.54847335,\n",
       "       0.47862049, 0.60308111, 0.60692858, 0.80263072, 0.66918302,\n",
       "       0.70756803, 0.63420833, 0.62071464, 0.72659022, 0.9153752 ])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63800754, 0.7486821 , 0.99665183, 0.62768006, 0.85312076,\n",
       "       0.61384574, 0.82511149, 0.82995873, 0.7140963 , 0.61211645,\n",
       "       0.48760757, 0.64185501, 0.84413368, 0.77116287, 0.78049058,\n",
       "       0.9153752 , 0.84759226, 0.85312076, 0.77635074, 0.97071248,\n",
       "       0.93612668, 0.72447204, 0.7300488 , 0.84898092, 0.47862049,\n",
       "       0.71967306, 0.75214068, 0.68301734, 0.91710449, 0.78153861,\n",
       "       0.92268125, 0.90292954, 0.54779209, 0.85450942, 0.86176721,\n",
       "       0.60653969, 0.61038716, 0.56196704, 0.71755488, 0.69719229,\n",
       "       0.66226586, 0.72140235, 0.7313892 , 0.73450715, 0.71241527,\n",
       "       0.67091231, 0.79091458, 0.72135409, 0.73696596, 0.765975  ,\n",
       "       0.64078486, 0.949961  , 0.87733082, 0.56715491, 0.97762964,\n",
       "       0.98973467, 0.45786901, 0.61730432, 0.48553765, 0.72140235,\n",
       "       0.79364364, 0.8178537 , 0.8351466 , 0.82857007, 0.94304384,\n",
       "       0.82684078, 0.76568264, 0.66879413, 0.62456211, 0.56196704,\n",
       "       0.71029709, 0.65218249, 0.87007303, 0.86488516, 0.89116514,\n",
       "       0.82822944, 0.68681655, 0.72554219, 0.63286793, 0.66745373,\n",
       "       0.57925994, 0.6553487 , 0.58271852, 0.91710449, 0.8524395 ,\n",
       "       0.6048104 , 0.88770656, 0.75386997, 0.7182844 , 0.69719229,\n",
       "       0.64151438, 0.80401938, 0.67432263, 0.53736809, 0.97762964,\n",
       "       0.84586297, 0.66399515, 0.85623871, 0.75598815, 0.76251642,\n",
       "       0.70410945, 0.70717914, 0.81166606, 0.82822944, 0.96345469,\n",
       "       0.87214295, 0.87906011, 0.69507411, 0.86695508, 0.81992362,\n",
       "       0.87214295, 0.63286793, 0.76943358, 0.65741862, 0.52392266,\n",
       "       0.81059591, 0.62595077, 0.68301734, 0.70165064, 0.71760314,\n",
       "       0.88770656, 0.73657707, 0.86627382, 0.95307895, 0.63839643,\n",
       "       0.58685836, 0.53741635, 0.5515913 , 0.75559926, 0.65841839,\n",
       "       0.7300488 , 0.52911053, 0.54428525, 0.70337993, 0.78845577,\n",
       "       0.69580363, 0.61591566, 0.66433578, 0.85139147, 0.63113864,\n",
       "       0.82511149, 0.83582786, 0.7715035 , 0.64146612, 0.90154088,\n",
       "       0.8289107 , 0.84966218, 0.67298223, 0.61484551, 0.88390735,\n",
       "       0.60347   , 0.43365895, 0.56369633, 0.93093881, 0.64324367,\n",
       "       0.73523667, 0.40214284, 0.81992362, 0.67916987, 0.6781701 ,\n",
       "       0.57200215, 0.66187697, 0.84932155, 0.7127559 , 0.67259334,\n",
       "       0.46132759, 0.72067283, 0.76458634, 0.78019821, 0.65150123,\n",
       "       0.65841839, 0.73177809, 0.80263072, 0.63800754, 0.89774167,\n",
       "       0.78533782, 0.64112549, 0.62974998, 0.8980823 , 0.92229236,\n",
       "       0.71621448, 0.71755488, 0.86488516, 0.85278013, 0.71170787,\n",
       "       0.89289443, 0.56196704, 0.66399515, 0.8116178 , 0.58098923,\n",
       "       0.7943249 , 0.78984443, 0.57373144, 0.71794377, 0.89981159,\n",
       "       0.77328105, 0.83548723, 0.67782947, 0.84240439, 0.7313892 ,\n",
       "       0.59136497, 0.60347   , 0.65741862, 0.5170055 , 0.82270094,\n",
       "       0.7313892 , 0.49659465, 0.84413368, 0.93924463, 0.65880728,\n",
       "       0.49591339, 0.5861771 , 0.67678144, 0.75425886, 0.75114091,\n",
       "       0.84759226, 0.68608703, 0.77635074, 0.62422148, 0.60726921,\n",
       "       0.87387224, 0.77673963, 0.67259334, 0.76358657, 0.98108822,\n",
       "       0.67471152, 0.71721425, 0.69719229, 0.83202865, 0.78360853,\n",
       "       0.77462145, 0.59828213, 0.76078713, 0.55297996, 0.47343262,\n",
       "       0.82511149, 0.67851073, 0.63459722, 0.52392266, 0.51666487,\n",
       "       0.64531359, 0.73869525, 0.85278013, 0.71760314, 0.69373371,\n",
       "       0.60999827, 0.68469837, 0.97071248, 0.91849315, 0.85901603,\n",
       "       0.82684078, 0.6836986 , 0.7486821 , 0.80820748, 0.62802069,\n",
       "       0.7140963 , 0.7127559 , 0.65875902, 0.52565195, 0.63800754,\n",
       "       0.60865787, 0.71375567, 0.77289216, 0.78533782, 0.63074975,\n",
       "       0.71967306, 0.85450942, 0.66399515, 0.80401938, 0.59136497,\n",
       "       0.89947096, 0.92575094, 0.59828213, 0.54155619, 0.62940935,\n",
       "       0.78499719, 0.65914791, 0.64704288, 0.60865787, 0.85623871,\n",
       "       0.76943358, 0.79018506, 0.62249219, 0.68681655, 0.4651268 ,\n",
       "       0.71582559, 0.62768006, 0.60035205, 0.98420617, 0.6968034 ,\n",
       "       0.81958299, 0.77462145, 0.8178537 , 0.64458407, 0.90845804,\n",
       "       0.72866014, 0.63113864, 0.90499946, 0.92056307, 0.5342984 ])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84898092, 0.93924463, 0.88424798, 0.68474663, 0.68401711,\n",
       "       0.52565195, 0.5688842 , 0.82995873, 0.65223075, 0.68988624,\n",
       "       0.511477  , 0.69339308, 0.52114534, 0.76977421, 0.7486821 ,\n",
       "       0.82995873, 0.56542562, 0.91157599, 0.79364364, 0.6380558 ,\n",
       "       0.5633557 , 0.93232747, 0.69200442, 0.75525863, 0.90465883,\n",
       "       0.73937651, 0.66947539, 0.83202865, 0.90154088, 0.5861771 ,\n",
       "       0.78360853, 0.62110353, 0.66053657, 0.52738124, 0.55125067,\n",
       "       0.94270321, 0.63800754, 0.54155619, 0.47204396, 0.6968034 ,\n",
       "       0.60381063, 0.85657934, 0.71621448, 0.89428309, 0.87906011,\n",
       "       0.46166822, 0.8047489 , 0.64704288, 0.76804492, 0.68988624,\n",
       "       0.71029709, 0.73311849, 0.56715491, 0.63493785, 0.75386997,\n",
       "       0.77362168, 0.7127559 , 0.67298223, 0.61138693, 0.96033674,\n",
       "       0.58924679, 0.52565195, 0.60726921, 0.76704515, 0.66740547,\n",
       "       0.86661445, 0.55470925, 0.7411058 , 0.94304384, 0.73869525,\n",
       "       0.73450715, 0.90154088, 0.50974771, 0.60692858, 0.79644308,\n",
       "       0.93751534, 0.97417106, 0.85105084, 0.64146612, 0.68335797,\n",
       "       0.7591061 , 0.7832679 , 0.4423054 , 0.67332286, 0.93924463,\n",
       "       0.91710449, 0.79230324, 0.64843154, 0.75214068, 0.54847335,\n",
       "       0.47862049, 0.60308111, 0.60692858, 0.80263072, 0.66918302,\n",
       "       0.70756803, 0.63420833, 0.62071464, 0.72659022, 0.9153752 ])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0.68 0.94 0.93 0.68 0.71 0.58 0.68 0.83 0.54 0.74 0.56 0.7  0.45 0.69\n 0.78 0.84 0.68 0.96 0.77 0.42 0.58 0.95 0.69 0.75 0.91 0.68 0.72 0.84\n 0.93 0.48 0.77 0.72 0.62 0.38 0.51 0.93 0.65 0.36 0.47 0.62 0.63 0.88\n 0.76 0.91 0.88 0.47 0.87 0.64 0.73 0.76 0.53 0.73 0.63 0.47 0.73 0.55\n 0.73 0.72 0.52 0.95 0.64 0.57 0.62 0.76 0.73 0.9  0.52 0.77 0.94 0.75\n 0.81 0.92 0.49 0.73 0.78 0.92 0.96 0.82 0.5  0.75 0.7  0.78 0.57 0.77\n 0.95 0.94 0.86 0.69 0.64 0.64 0.57 0.44 0.64 0.76 0.71 0.56 0.64 0.64\n 0.72 0.93].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-e02eb57e09db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \"\"\"\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"coef_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m    206\u001b[0m                                dense_output=True) + self.intercept_\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    519\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[1;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.68 0.94 0.93 0.68 0.71 0.58 0.68 0.83 0.54 0.74 0.56 0.7  0.45 0.69\n 0.78 0.84 0.68 0.96 0.77 0.42 0.58 0.95 0.69 0.75 0.91 0.68 0.72 0.84\n 0.93 0.48 0.77 0.72 0.62 0.38 0.51 0.93 0.65 0.36 0.47 0.62 0.63 0.88\n 0.76 0.91 0.88 0.47 0.87 0.64 0.73 0.76 0.53 0.73 0.63 0.47 0.73 0.55\n 0.73 0.72 0.52 0.95 0.64 0.57 0.62 0.76 0.73 0.9  0.52 0.77 0.94 0.75\n 0.81 0.92 0.49 0.73 0.78 0.92 0.96 0.82 0.5  0.75 0.7  0.78 0.57 0.77\n 0.95 0.94 0.86 0.69 0.64 0.64 0.57 0.44 0.64 0.76 0.71 0.56 0.64 0.64\n 0.72 0.93].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "c.predict(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7570532075037095"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
